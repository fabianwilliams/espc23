{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9939cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv \n",
    "from azure.identity import DeviceCodeCredential\n",
    "from msgraph import GraphServiceClient\n",
    "from msgraph.generated.users.item.messages.messages_request_builder import MessagesRequestBuilder\n",
    "from msgraph.generated.search.query.query_post_request_body import QueryPostRequestBody\n",
    "from msgraph.generated.search.query.query_request_builder import QueryRequestBuilder\n",
    "from msgraph.generated.search.search_request_builder import SearchRequestBuilder\n",
    "from msgraph.generated.models.search_request import SearchRequest\n",
    "from msgraph.generated.models.entity_type import EntityType\n",
    "from msgraph.generated.models.search_query import SearchQuery\n",
    "from msgraph.generated.models.search_response import SearchResponse\n",
    "import os\n",
    "import json\n",
    "import asyncio \n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062da045-9a25-482d-979f-1c7a51f890da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620ccb68-90d9-4ffc-8cbf-af0fe3830133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': <semantic_kernel.orchestration.sk_function.SKFunction at 0x115217d10>,\n",
       " 'save': <semantic_kernel.orchestration.sk_function.SKFunction at 0x115217110>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "#kernel.add_chat_service(\"chat-gpt\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))\n",
    "kernel.add_chat_service(\"chat-gpt\", OpenAIChatCompletion(\"gpt-4\", api_key, org_id))\n",
    "kernel.add_text_embedding_generation_service(\"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id))\n",
    "\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18e1db1-c633-4aeb-882e-954b3ee4d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(org_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc30b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad04896-dd1b-49d0-a3ca-a06deac6e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION = \"ESPC23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191c4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENANT_ID = os.getenv(\"TENANT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e9b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232c7384-3c6a-4d70-a261-63c2cbe766a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphUserScopes = os.getenv(\"graphUserScopes\").split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0761080e-8ae2-4bce-a2bd-48d1232ad72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(CLIENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac18b09-99be-4e04-a1f8-47da395dfa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gabby = '9c72876c-b0ec-41b3-8079-8ebe216daa34'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7714c8f0-acff-4355-bdc8-3b2dfb5227c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fabs = 'fabian@fabster.onmicrosoft.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d304a16-7dbc-4b0d-9b06-df920af112b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure that you have turned on DefaultClientType to Yes in the App Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a96b477-9d74-461c-91ad-dc77d7e5dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User.Read', 'Mail.ReadWrite', 'Chat.ReadWrite', 'Calendars.Read', 'Files.Read.All', 'Sites.Read.All']\n"
     ]
    }
   ],
   "source": [
    "print(graphUserScopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d1c165-7ec9-4cfe-a8eb-44940a3a81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DeviceCodeCredential(client_id=CLIENT_ID, tenant_id=TENANT_ID) \n",
    "scopes = graphUserScopes\n",
    "client = GraphServiceClient(credentials=credential, scopes=scopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4be0a9d-ab67-47ce-ba1c-899e991e85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await client.me.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64fdaf30-0b99-45a1-887c-96a80cf94b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabby Gabgab\n"
     ]
    }
   ],
   "source": [
    "print(result.display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc18d6-0b29-48fc-b460-3dc85df584df",
   "metadata": {},
   "source": [
    "## Do the Query and Get the Intent of the User Asking the Question (UserPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0177a67-77e4-4008-91b2-9161ea0eb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: Using a File to Run these Plugins instead of Inline to \n",
    "# show a different way\n",
    "plugins_directory = \"Plugins/\"\n",
    "intentFunctions = kernel.import_semantic_skill_from_directory(plugins_directory, \"HoldMyHandPlugin\")\n",
    "\n",
    "getIntentFunction = intentFunctions[\"GetIntent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d05d23d4-13bd-4899-a0c3-f497dfbfe717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"subject\": \"Gabby\", \"action\": \"know what was accomplished during the ESPC demo in Antwerp\"}\n"
     ]
    }
   ],
   "source": [
    "userIntent = getIntentFunction(\"What did I accomplish this weekend with Gabby in Antwerp regarding our ESPC demo?\")\n",
    "\n",
    "print(userIntent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f96c73c-9125-4dba-b8aa-c589af3c588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': 'Gabby', 'action': 'know what was accomplished during the ESPC demo in Antwerp'}\n"
     ]
    }
   ],
   "source": [
    "subject_data = json.loads(str(userIntent))\n",
    "print(subject_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9383472-1f16-422e-9f5d-b4b630ef43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = subject_data['subject']\n",
    "action = subject_data['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "306cb509-d90d-4d9d-a98c-fdfa3eec8cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabby\n"
     ]
    }
   ],
   "source": [
    "print(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28cf6a56-ed18-4841-8550-ed8256107e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "know what was accomplished during the ESPC demo in Antwerp\n"
     ]
    }
   ],
   "source": [
    "print(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5adac-29fd-4455-ae32-1f51f4733d6c",
   "metadata": {},
   "source": [
    "## Work with Teams(Chat) Search Query Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c16bdd-4c1a-4aa6-908d-6e44375c03be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a3e21b7-fbf4-42ec-a251-e31b32bdfd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = QueryPostRequestBody(\n",
    "\trequests = [\n",
    "\t\tSearchRequest(\n",
    "\t\t\tentity_types = [\n",
    "\t\t\t\tEntityType.ChatMessage\n",
    "\t\t\t],\n",
    "\t\t\tquery = SearchQuery(\n",
    "\t\t\t\tquery_string = subject,\n",
    "\t\t\t),\n",
    "\t\t),\n",
    "\t],\n",
    ")\n",
    "\n",
    "chat_result = await client.search.query.post(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "836cd186-7f0a-4692-acd0-3ca014e9334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data = chat_result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b04027d4-5772-4e1e-a7ef-0b0b26e1afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing with GUID\n",
    "search_response = chat_data[0] \n",
    "\n",
    "# Initialize an empty list to store summaries, chat IDs, and generated GUIDs\n",
    "summaries_chat_ids_and_guids = []\n",
    "\n",
    "# Iterate over hits_containers in the SearchResponse object\n",
    "for hits_container in search_response.hits_containers:\n",
    "    # Iterate over each hit in the container\n",
    "    for hit in hits_container.hits:\n",
    "        # Extract the summary\n",
    "        summary = hit.summary\n",
    "\n",
    "        # Extract the chatId from additional_data\n",
    "        chat_id = hit.resource.additional_data.get('chatId', 'Unknown')\n",
    "\n",
    "        # Generate a unique GUID for each hit\n",
    "        guid = str(uuid.uuid4())\n",
    "\n",
    "        # Append the chatId, summary, and GUID as a tuple to the list\n",
    "        summaries_chat_ids_and_guids.append((guid, summary))\n",
    "\n",
    "# Now 'summaries_chat_ids_and_guids' contains the chatId, summary, and a unique GUID for each search hit\n",
    "for item in summaries_chat_ids_and_guids:\n",
    "    await kernel.memory.save_information_async(\"ESPC23\", id=guid, text=summary)\n",
    "    #print(item)\n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3f1fe-a3e5-476a-81b7-80559735ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(summaries_chat_ids_and_guids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4e601-69a4-4875-93fc-91a1debbbadc",
   "metadata": {},
   "source": [
    "## Work with Drives(Files) Search Query Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf822fd-c39e-4a24-b090-d06896c664b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf195b7-2e7f-4862-b363-85db4e6f1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = QueryPostRequestBody(\n",
    "\trequests = [\n",
    "\t\tSearchRequest(\n",
    "\t\t\tentity_types = [\n",
    "\t\t\t\tEntityType.DriveItem\n",
    "\t\t\t],\n",
    "\t\t\tquery = SearchQuery(\n",
    "\t\t\t\tquery_string = subject,\n",
    "\t\t\t),\n",
    "\t\t),\n",
    "\t],\n",
    ")\n",
    "\n",
    "drive_result = await client.search.query.post(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c37d9da2-9668-4257-9efe-10cb4d9ef77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_data = drive_result.value\n",
    "#print(drive_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dfba2c2-e11b-435c-9f66-8b3af4a2bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    drive_search_response = drive_data[0]  # Assuming there's only one SearchResponse object in the list\n",
    "\n",
    "    # Initialize an empty list to store summaries, from information, and generated GUIDs\n",
    "    drive_summary_from_and_guids = []\n",
    "    drive_narrative = []\n",
    "\n",
    "    if drive_search_response:\n",
    "        # Iterate over hits_containers in the SearchResponse object\n",
    "        for drive_hits_container in drive_search_response.hits_containers:\n",
    "            # Iterate over each hit in the container\n",
    "            for drive_hit in drive_hits_container.hits:\n",
    "                # Extract the summary\n",
    "                drive_summary = drive_hit.summary\n",
    "\n",
    "                # Extract the 'from' information from additional_data\n",
    "                from_data = drive_hit.resource.additional_data.get('from', {}).get('emailAddress', {})\n",
    "                from_name = from_data.get('name', 'Unknown')\n",
    "                from_email = from_data.get('address', 'Unknown')\n",
    "                file_name = getattr(drive_hit.resource, 'name', 'Unknown')\n",
    "                user_email = from_data.get('email', 'Unknown')\n",
    "\n",
    "                # Generate a unique GUID for each hit\n",
    "                drive_guid = str(uuid.uuid4())\n",
    "\n",
    "                # Append the summary, 'from' information, and GUID as a tuple to the list\n",
    "                drive_summary_from_and_guids.append((drive_guid, drive_summary, from_name, from_email))\n",
    "                drive_narrative.append((drive_guid, file_name))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Now 'drive_summary_from_and_guids' contains the summary, from information, and a unique GUID for each search hit\n",
    "for item in drive_narrative:\n",
    "    await kernel.memory.save_information_async(\"ESPC23\", id=drive_guid, text=file_name)\n",
    "    #print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5aa2ab9-2669-49c7-b6b6-e3946e06d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(drive_narrative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67855070-c562-4f8e-837a-214904ff14e2",
   "metadata": {},
   "source": [
    "## Work with Messages(Email) Search Query Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0d1fa17-ee01-4347-9363-251cec125b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = QueryPostRequestBody(\n",
    "\trequests = [\n",
    "\t\tSearchRequest(\n",
    "\t\t\tentity_types = [\n",
    "\t\t\t\tEntityType.Message\n",
    "\t\t\t],\n",
    "\t\t\tquery = SearchQuery(\n",
    "\t\t\t\tquery_string = subject,\n",
    "\t\t\t),\n",
    "\t\t),\n",
    "\t],\n",
    ")\n",
    "\n",
    "mail_result = await client.search.query.post(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f674c27b-fe6e-4c6b-9bd3-19ac88bfedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_data = mail_result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fc38502-2c74-421a-987e-fd789457831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mail_search_response = mail_data[0]  # Assuming there's only one SearchResponse object in the list\n",
    "\n",
    "    # Initialize an empty list to store summaries, from information, and generated GUIDs\n",
    "    mail_summary_from_and_guids = []\n",
    "\n",
    "    if mail_search_response:\n",
    "        # Iterate over hits_containers in the SearchResponse object\n",
    "        for mail_hits_container in mail_search_response.hits_containers:\n",
    "            # Iterate over each hit in the container\n",
    "            for mail_hit in mail_hits_container.hits:\n",
    "                # Extract the summary\n",
    "                mail_summary = mail_hit.summary\n",
    "\n",
    "                # Extract the 'from' information from additional_data\n",
    "                from_data = mail_hit.resource.additional_data.get('from', {}).get('emailAddress', {})\n",
    "                from_name = from_data.get('name', 'Unknown')\n",
    "                from_email = from_data.get('address', 'Unknown')\n",
    "\n",
    "                # Generate a unique GUID for each hit\n",
    "                guid = str(uuid.uuid4())\n",
    "\n",
    "                # Append the summary, 'from' information, and GUID as a tuple to the list\n",
    "                mail_summary_from_and_guids.append((guid, mail_summary, from_name, from_email))\n",
    "                mailconstruct = mail_summary + \" from \" + from_name\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Now 'mail_summary_from_and_guids' contains the summary, from information, and a unique GUID for each search hit\n",
    "for item in mail_summary_from_and_guids:\n",
    "    await kernel.memory.save_information_async(\"ESPC23\", id=guid, text=mailconstruct)\n",
    "    #print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b7b9ab6-acd8-411c-b831-337758494522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mail_summary_from_and_guids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0fbd00-44ba-4d88-957e-4cb191685c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bb0c3da-ed93-445b-87fa-76eb60e71743",
   "metadata": {},
   "source": [
    "## Query and Read All 3 Payloads from Semantic Memory ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d8ccb18-c337-4834-8cb2-34bc5f997410",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_memory_examples(kernel: sk.Kernel) -> None:\n",
    "    questions = [\n",
    "        \"Whats going on with Gabby\",\n",
    "        \"What conferences are we doing\",\n",
    "    ]\n",
    "\n",
    "    for question in questions:\n",
    "        results = await kernel.memory.search_async(\"ESPC23\", question, limit=3)\n",
    "        for result in results:\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Answer: {result.text}\\nRelevance: {result.relevance}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4172004c-2651-47cb-9dea-967f4db8ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Whats going on with Gabby\n",
      "Answer: hello Gabby, are you prepared for the ChatGPT session with Python?\n",
      "Relevance: 0.8015434058556261\n",
      "\n",
      "Question: Whats going on with Gabby\n",
      "Answer: Ok, So make sure you know your lines, study your answers to the questions. Get your demo ready to go. MOST IMPORTANT: do all the sacrifices to the demo gods!!! Dad. from Unknown\n",
      "Relevance: 0.7223546610199888\n",
      "\n",
      "Question: Whats going on with Gabby\n",
      "Answer: HowToGainAccessToStudyGroup.docx\n",
      "Relevance: 0.7196357848102334\n",
      "\n",
      "Question: What conferences are we doing\n",
      "Answer: HowToGainAccessToStudyGroup.docx\n",
      "Relevance: 0.7515025470786859\n",
      "\n",
      "Question: What conferences are we doing\n",
      "Answer: hello Gabby, are you prepared for the ChatGPT session with Python?\n",
      "Relevance: 0.7329083577823825\n",
      "\n",
      "Question: What conferences are we doing\n",
      "Answer: Ok, So make sure you know your lines, study your answers to the questions. Get your demo ready to go. MOST IMPORTANT: do all the sacrifices to the demo gods!!! Dad. from Unknown\n",
      "Relevance: 0.7307060801506872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await search_memory_examples(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c30df-4ad8-4ef1-b69b-fde4c1925df7",
   "metadata": {},
   "source": [
    "## Setup RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "336dbd6c-8abb-49c1-9475-6acba5e58026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPC23\n"
     ]
    }
   ],
   "source": [
    "print(COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "281efd08-2cd5-42d8-919e-9388b56d54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_RAG(kernel: sk.Kernel) -> Tuple[sk.SKFunctionBase, sk.SKContext]:\n",
    "    sk_prompt = \"\"\"\n",
    "    You are a friendly and very talkative ChatBot. \n",
    "    \n",
    "    {{$history}}\n",
    "    Answer the {{$user_input}}. You may use information provided in {{$retreived_context}} it may be useful. \n",
    "    Return complete answers wiht prices only from {{$retreived_context}} otherwise say 'I have no reccomendations for you'. \n",
    "    ChatBot:\"\"\".strip()\n",
    "\n",
    "    rag_func = kernel.create_semantic_function(sk_prompt, max_tokens=2000, temperature=0.1)\n",
    "\n",
    "    context = kernel.create_new_context()\n",
    "\n",
    "    return rag_func, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51b6261a-1b88-43ef-9e02-097af6f5cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def RAG(kernel: sk.Kernel, rag_func: sk.SKFunctionBase, context: sk.SKContext) -> bool:\n",
    "\n",
    "    user_input = input(\"User:> \")\n",
    "    context[\"user_input\"] = user_input\n",
    "    #Retrieve\n",
    "    result = await kernel.memory.search_async(COLLECTION,context[\"user_input\"])\n",
    "\n",
    "    \n",
    "    if result[0].text:\n",
    "        context[\"retreived_context\"] = result[0].text\n",
    "    \n",
    "    #Then generate\n",
    "    answer = await kernel.run_async(rag_func, input_vars=context.variables)\n",
    "\n",
    "    print(f\"\\n\\u001b[34mChatBot:> {answer}\\u001b[0m \\n\\n\\033[1;32m Source: {context['retreived_context']}\\n Relevance: {result[0].relevance}\\u001b[0m \\n\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab818459-9f37-4591-9089-557f74f2c056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulate Chat experience with SK and RAG\n"
     ]
    }
   ],
   "source": [
    "print(\"Simulate Chat experience with SK and RAG\")\n",
    "rag_func, context = await setup_RAG(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7765a1b2-4dfa-4954-a6ff-3105499a4e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question (type 'exit' to exit):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:>  What did fabian and gabby work on \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mChatBot:> Based on the information provided, Fabian and Gabby worked on a ChatGPT session with Python.\u001b[0m \n",
      "\n",
      "\u001b[1;32m Source: hello Gabby, are you prepared for the ChatGPT session with Python?\n",
      " Relevance: 0.7917456309860029\u001b[0m \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ask a question (type 'exit' to exit):\\n\")\n",
    "answer = await RAG(kernel, rag_func, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b63ca-e4d3-4f3b-b043-2f86dba5a489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espc23",
   "language": "python",
   "name": "espc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
