{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9939cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv \n",
    "from azure.identity import DeviceCodeCredential\n",
    "from msgraph import GraphServiceClient\n",
    "from msgraph.generated.users.item.messages.messages_request_builder import MessagesRequestBuilder\n",
    "from msgraph.generated.search.query.query_post_request_body import QueryPostRequestBody\n",
    "from msgraph.generated.search.query.query_request_builder import QueryRequestBuilder\n",
    "from msgraph.generated.search.search_request_builder import SearchRequestBuilder\n",
    "from msgraph.generated.models.search_request import SearchRequest\n",
    "from msgraph.generated.models.entity_type import EntityType\n",
    "from msgraph.generated.models.search_query import SearchQuery\n",
    "from msgraph.generated.models.search_response import SearchResponse\n",
    "import os\n",
    "import json\n",
    "import asyncio \n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062da045-9a25-482d-979f-1c7a51f890da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620ccb68-90d9-4ffc-8cbf-af0fe3830133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': <semantic_kernel.orchestration.sk_function.SKFunction at 0x115217d10>,\n",
       " 'save': <semantic_kernel.orchestration.sk_function.SKFunction at 0x115217110>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "#kernel.add_chat_service(\"chat-gpt\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))\n",
    "kernel.add_chat_service(\"chat-gpt\", OpenAIChatCompletion(\"gpt-4\", api_key, org_id))\n",
    "kernel.add_text_embedding_generation_service(\"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id))\n",
    "\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18e1db1-c633-4aeb-882e-954b3ee4d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(org_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc30b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad04896-dd1b-49d0-a3ca-a06deac6e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION = \"ESPC23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191c4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENANT_ID = os.getenv(\"TENANT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e9b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232c7384-3c6a-4d70-a261-63c2cbe766a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphUserScopes = os.getenv(\"graphUserScopes\").split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0761080e-8ae2-4bce-a2bd-48d1232ad72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(CLIENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac18b09-99be-4e04-a1f8-47da395dfa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gabby = '9c72876c-b0ec-41b3-8079-8ebe216daa34'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7714c8f0-acff-4355-bdc8-3b2dfb5227c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fabs = 'fabian@fabster.onmicrosoft.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d304a16-7dbc-4b0d-9b06-df920af112b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure that you have turned on DefaultClientType to Yes in the App Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a96b477-9d74-461c-91ad-dc77d7e5dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User.Read', 'Mail.ReadWrite', 'Chat.ReadWrite', 'Calendars.Read', 'Files.Read.All', 'Sites.Read.All']\n"
     ]
    }
   ],
   "source": [
    "print(graphUserScopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d1c165-7ec9-4cfe-a8eb-44940a3a81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DeviceCodeCredential(client_id=CLIENT_ID, tenant_id=TENANT_ID) \n",
    "scopes = graphUserScopes\n",
    "client = GraphServiceClient(credentials=credential, scopes=scopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4be0a9d-ab67-47ce-ba1c-899e991e85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await client.me.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64fdaf30-0b99-45a1-887c-96a80cf94b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabby Gabgab\n"
     ]
    }
   ],
   "source": [
    "print(result.display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc18d6-0b29-48fc-b460-3dc85df584df",
   "metadata": {},
   "source": [
    "## Do the Query and Get the Intent of the User Asking the Question (UserPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0177a67-77e4-4008-91b2-9161ea0eb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: Using a File to Run these Plugins instead of Inline to \n",
    "# show a different way\n",
    "plugins_directory = \"Plugins/\"\n",
    "intentFunctions = kernel.import_semantic_skill_from_directory(plugins_directory, \"HoldMyHandPlugin\")\n",
    "\n",
    "getIntentFunction = intentFunctions[\"GetIntent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d05d23d4-13bd-4899-a0c3-f497dfbfe717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"subject\": \"Gabby\", \"action\": \"know what was accomplished during the ESPC demo in Antwerp\"}\n"
     ]
    }
   ],
   "source": [
    "userIntent = getIntentFunction(\"What did I accomplish this weekend with Gabby in Antwerp regarding our ESPC demo?\")\n",
    "\n",
    "print(userIntent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f96c73c-9125-4dba-b8aa-c589af3c588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': 'Gabby', 'action': 'know what was accomplished during the ESPC demo in Antwerp'}\n"
     ]
    }
   ],
   "source": [
    "subject_data = json.loads(str(userIntent))\n",
    "print(subject_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9383472-1f16-422e-9f5d-b4b630ef43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = subject_data['subject']\n",
    "action = subject_data['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "306cb509-d90d-4d9d-a98c-fdfa3eec8cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabby\n"
     ]
    }
   ],
   "source": [
    "print(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28cf6a56-ed18-4841-8550-ed8256107e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "know what was accomplished during the ESPC demo in Antwerp\n"
     ]
    }
   ],
   "source": [
    "print(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5adac-29fd-4455-ae32-1f51f4733d6c",
   "metadata": {},
   "source": [
    "## Work with Teams(Chat) Search Query Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c16bdd-4c1a-4aa6-908d-6e44375c03be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a3e21b7-fbf4-42ec-a251-e31b32bdfd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = QueryPostRequestBody(\n",
    "\trequests = [\n",
    "\t\tSearchRequest(\n",
    "\t\t\tentity_types = [\n",
    "\t\t\t\tEntityType.ChatMessage\n",
    "\t\t\t],\n",
    "\t\t\tquery = SearchQuery(\n",
    "\t\t\t\tquery_string = subject,\n",
    "\t\t\t),\n",
    "\t\t),\n",
    "\t],\n",
    ")\n",
    "\n",
    "chat_result = await client.search.query.post(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "836cd186-7f0a-4692-acd0-3ca014e9334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data = chat_result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b04027d4-5772-4e1e-a7ef-0b0b26e1afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing with GUID\n",
    "search_response = chat_data[0]  # Assuming there's only one SearchResponse object in the list\n",
    "\n",
    "# Initialize an empty list to store summaries, chat IDs, and generated GUIDs\n",
    "summaries_chat_ids_and_guids = []\n",
    "\n",
    "# Iterate over hits_containers in the SearchResponse object\n",
    "for hits_container in search_response.hits_containers:\n",
    "    # Iterate over each hit in the container\n",
    "    for hit in hits_container.hits:\n",
    "        # Extract the summary\n",
    "        summary = hit.summary\n",
    "\n",
    "        # Extract the chatId from additional_data\n",
    "        chat_id = hit.resource.additional_data.get('chatId', 'Unknown')\n",
    "\n",
    "        # Generate a unique GUID for each hit\n",
    "        guid = str(uuid.uuid4())\n",
    "\n",
    "        # Append the chatId, summary, and GUID as a tuple to the list\n",
    "        summaries_chat_ids_and_guids.append((guid, summary))\n",
    "\n",
    "# Now 'summaries_chat_ids_and_guids' contains the chatId, summary, and a unique GUID for each search hit\n",
    "for item in summaries_chat_ids_and_guids:\n",
    "    await kernel.memory.save_information_async(\"ESPC23\", id=guid, text=summary)\n",
    "    #print(item)\n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3f1fe-a3e5-476a-81b7-80559735ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(summaries_chat_ids_and_guids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4e601-69a4-4875-93fc-91a1debbbadc",
   "metadata": {},
   "source": [
    "## Work with Drives(Files) Search Query Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf822fd-c39e-4a24-b090-d06896c664b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf195b7-2e7f-4862-b363-85db4e6f1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = QueryPostRequestBody(\n",
    "\trequests = [\n",
    "\t\tSearchRequest(\n",
    "\t\t\tentity_types = [\n",
    "\t\t\t\tEntityType.DriveItem\n",
    "\t\t\t],\n",
    "\t\t\tquery = SearchQuery(\n",
    "\t\t\t\tquery_string = subject,\n",
    "\t\t\t),\n",
    "\t\t),\n",
    "\t],\n",
    ")\n",
    "\n",
    "drive_result = await client.search.query.post(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c37d9da2-9668-4257-9efe-10cb4d9ef77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_data = drive_result.value\n",
    "#print(drive_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dfba2c2-e11b-435c-9f66-8b3af4a2bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    drive_search_response = drive_data[0]  # Assuming there's only one SearchResponse object in the list\n",
    "\n",
    "    # Initialize an empty list to store summaries, from information, and generated GUIDs\n",
    "    drive_summary_from_and_guids = []\n",
    "    drive_narrative = []\n",
    "\n",
    "    if drive_search_response:\n",
    "        # Iterate over hits_containers in the SearchResponse object\n",
    "        for drive_hits_container in drive_search_response.hits_containers:\n",
    "            # Iterate over each hit in the container\n",
    "            for drive_hit in drive_hits_container.hits:\n",
    "                # Extract the summary\n",
    "                drive_summary = drive_hit.summary\n",
    "\n",
    "                # Extract the 'from' information from additional_data\n",
    "                from_data = drive_hit.resource.additional_data.get('from', {}).get('emailAddress', {})\n",
    "                from_name = from_data.get('name', 'Unknown')\n",
    "                from_email = from_data.get('address', 'Unknown')\n",
    "                file_name = getattr(drive_hit.resource, 'name', 'Unknown')\n",
    "                user_email = from_data.get('email', 'Unknown')\n",
    "\n",
    "                # Generate a unique GUID for each hit\n",
    "                drive_guid = str(uuid.uuid4())\n",
    "\n",
    "                # Append the summary, 'from' information, and GUID as a tuple to the list\n",
    "                drive_summary_from_and_guids.append((drive_guid, drive_summary, from_name, from_email))\n",
    "                drive_narrative.append((drive_guid, file_name))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Now 'drive_summary_from_and_guids' contains the summary, from information, and a unique GUID for each search hit\n",
    "for item in drive_narrative:\n",
    "    await kernel.memory.save_information_async(\"ESPC23\", id=drive_guid, text=file_name)\n",
    "    #print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5aa2ab9-2669-49c7-b6b6-e3946e06d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(drive_narrative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67855070-c562-4f8e-837a-214904ff14e2",
   "metadata": {},
   "source": [
    "## Work with Messages(Email) Search Query Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0d1fa17-ee01-4347-9363-251cec125b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = QueryPostRequestBody(\n",
    "\trequests = [\n",
    "\t\tSearchRequest(\n",
    "\t\t\tentity_types = [\n",
    "\t\t\t\tEntityType.Message\n",
    "\t\t\t],\n",
    "\t\t\tquery = SearchQuery(\n",
    "\t\t\t\tquery_string = subject,\n",
    "\t\t\t),\n",
    "\t\t),\n",
    "\t],\n",
    ")\n",
    "\n",
    "mail_result = await client.search.query.post(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f674c27b-fe6e-4c6b-9bd3-19ac88bfedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_data = mail_result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fc38502-2c74-421a-987e-fd789457831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mail_search_response = mail_data[0]  # Assuming there's only one SearchResponse object in the list\n",
    "\n",
    "    # Initialize an empty list to store summaries, from information, and generated GUIDs\n",
    "    mail_summary_from_and_guids = []\n",
    "\n",
    "    if mail_search_response:\n",
    "        # Iterate over hits_containers in the SearchResponse object\n",
    "        for mail_hits_container in mail_search_response.hits_containers:\n",
    "            # Iterate over each hit in the container\n",
    "            for mail_hit in mail_hits_container.hits:\n",
    "                # Extract the summary\n",
    "                mail_summary = mail_hit.summary\n",
    "\n",
    "                # Extract the 'from' information from additional_data\n",
    "                from_data = mail_hit.resource.additional_data.get('from', {}).get('emailAddress', {})\n",
    "                from_name = from_data.get('name', 'Unknown')\n",
    "                from_email = from_data.get('address', 'Unknown')\n",
    "\n",
    "                # Generate a unique GUID for each hit\n",
    "                guid = str(uuid.uuid4())\n",
    "\n",
    "                # Append the summary, 'from' information, and GUID as a tuple to the list\n",
    "                mail_summary_from_and_guids.append((guid, mail_summary, from_name, from_email))\n",
    "                mailconstruct = mail_summary + \" from \" + from_name\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Now 'mail_summary_from_and_guids' contains the summary, from information, and a unique GUID for each search hit\n",
    "for item in mail_summary_from_and_guids:\n",
    "    await kernel.memory.save_information_async(\"ESPC23\", id=guid, text=mailconstruct)\n",
    "    #print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b7b9ab6-acd8-411c-b831-337758494522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mail_summary_from_and_guids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0fbd00-44ba-4d88-957e-4cb191685c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bb0c3da-ed93-445b-87fa-76eb60e71743",
   "metadata": {},
   "source": [
    "## Query and Read All 3 Payloads from Semantic Memory ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d8ccb18-c337-4834-8cb2-34bc5f997410",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_memory_examples(kernel: sk.Kernel) -> None:\n",
    "    questions = [\n",
    "        \"Whats going on with Gabby\",\n",
    "        \"What conferences are we doing\",\n",
    "    ]\n",
    "\n",
    "    for question in questions:\n",
    "        results = await kernel.memory.search_async(\"ESPC23\", question, limit=3)\n",
    "        for result in results:\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Answer: {result.text}\\nRelevance: {result.relevance}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4172004c-2651-47cb-9dea-967f4db8ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Whats going on with Gabby\n",
      "Answer: hello Gabby, are you prepared for the ChatGPT session with Python?\n",
      "Relevance: 0.8015434058556261\n",
      "\n",
      "Question: Whats going on with Gabby\n",
      "Answer: Ok, So make sure you know your lines, study your answers to the questions. Get your demo ready to go. MOST IMPORTANT: do all the sacrifices to the demo gods!!! Dad. from Unknown\n",
      "Relevance: 0.7223546610199888\n",
      "\n",
      "Question: Whats going on with Gabby\n",
      "Answer: HowToGainAccessToStudyGroup.docx\n",
      "Relevance: 0.7196357848102334\n",
      "\n",
      "Question: What conferences are we doing\n",
      "Answer: HowToGainAccessToStudyGroup.docx\n",
      "Relevance: 0.7515025470786859\n",
      "\n",
      "Question: What conferences are we doing\n",
      "Answer: hello Gabby, are you prepared for the ChatGPT session with Python?\n",
      "Relevance: 0.7329083577823825\n",
      "\n",
      "Question: What conferences are we doing\n",
      "Answer: Ok, So make sure you know your lines, study your answers to the questions. Get your demo ready to go. MOST IMPORTANT: do all the sacrifices to the demo gods!!! Dad. from Unknown\n",
      "Relevance: 0.7307060801506872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await search_memory_examples(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c30df-4ad8-4ef1-b69b-fde4c1925df7",
   "metadata": {},
   "source": [
    "## Setup RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "336dbd6c-8abb-49c1-9475-6acba5e58026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPC23\n"
     ]
    }
   ],
   "source": [
    "print(COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "281efd08-2cd5-42d8-919e-9388b56d54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_RAG(kernel: sk.Kernel) -> Tuple[sk.SKFunctionBase, sk.SKContext]:\n",
    "    sk_prompt = \"\"\"\n",
    "    You are a friendly and very talkative ChatBot. \n",
    "    \n",
    "    {{$history}}\n",
    "    Answer the {{$user_input}}. You may use information provided in {{$retreived_context}} it may be useful. \n",
    "    Return complete answers wiht prices only from {{$retreived_context}} otherwise say 'I have no reccomendations for you'. \n",
    "    ChatBot:\"\"\".strip()\n",
    "\n",
    "    rag_func = kernel.create_semantic_function(sk_prompt, max_tokens=2000, temperature=0.1)\n",
    "\n",
    "    context = kernel.create_new_context()\n",
    "\n",
    "    return rag_func, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51b6261a-1b88-43ef-9e02-097af6f5cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def RAG(kernel: sk.Kernel, rag_func: sk.SKFunctionBase, context: sk.SKContext) -> bool:\n",
    "\n",
    "    user_input = input(\"User:> \")\n",
    "    context[\"user_input\"] = user_input\n",
    "    #Retrieve\n",
    "    result = await kernel.memory.search_async(COLLECTION,context[\"user_input\"])\n",
    "\n",
    "    \n",
    "    if result[0].text:\n",
    "        context[\"retreived_context\"] = result[0].text\n",
    "    \n",
    "    #Then generate\n",
    "    answer = await kernel.run_async(rag_func, input_vars=context.variables)\n",
    "\n",
    "    print(f\"\\n\\u001b[34mChatBot:> {answer}\\u001b[0m \\n\\n\\033[1;32m Source: {context['retreived_context']}\\n Relevance: {result[0].relevance}\\u001b[0m \\n\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab818459-9f37-4591-9089-557f74f2c056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulate Chat experience with SK and RAG\n"
     ]
    }
   ],
   "source": [
    "print(\"Simulate Chat experience with SK and RAG\")\n",
    "rag_func, context = await setup_RAG(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7765a1b2-4dfa-4954-a6ff-3105499a4e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question (type 'exit' to exit):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:>  What work do I need to prepare for this week in Amsterdam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mChatBot:> Based on the information provided, it seems like you have a presentation or a performance in Amsterdam this week. Here's what you need to do:\n",
      "\n",
      "1. Know Your Lines: Spend time rehearsing and memorizing your lines. This will help you deliver your presentation smoothly and confidently.\n",
      "\n",
      "2. Study Your Answers: Anticipate the questions that might be asked and prepare your answers. This will show that you are well-prepared and knowledgeable.\n",
      "\n",
      "3. Get Your Demo Ready: If you have a demo to present, make sure it's ready to go. Test it multiple times to ensure it works perfectly.\n",
      "\n",
      "4. Sacrifices to the Demo Gods: This is a humorous way of saying you should do everything you can to ensure your demo goes smoothly. This could include testing it on different devices, making sure you have all necessary equipment, and having a backup plan in case something goes wrong.\n",
      "\n",
      "Remember, preparation is key to a successful presentation. Good luck!\u001b[0m \n",
      "\n",
      "\u001b[1;32m Source: Ok, So make sure you know your lines, study your answers to the questions. Get your demo ready to go. MOST IMPORTANT: do all the sacrifices to the demo gods!!! Dad. from Unknown\n",
      " Relevance: 0.7669787694785052\u001b[0m \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ask a question (type 'exit' to exit):\\n\")\n",
    "answer = await RAG(kernel, rag_func, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b63ca-e4d3-4f3b-b043-2f86dba5a489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espc23",
   "language": "python",
   "name": "espc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
